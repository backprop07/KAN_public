{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matrixA_empty = torch.tensor([[-1,3,-3,1],\n",
    "                            [3,-6,3,0],\n",
    "                            [-3,0,3,0],\n",
    "                            [1,4,1,0]],dtype=torch.float32, requires_grad=False)/6\n",
    "\n",
    "coef_win_empty = torch.zeros(5,5,requires_grad=False,dtype=torch.int32)\n",
    "\n",
    "win_matrix_base = torch.tensor([0,1,2,3],requires_grad=False,dtype=torch.float)\n",
    "\n",
    "win_matrix_empty = win_matrix_base.repeat(16).int()\n",
    "\n",
    "x_index_empty = torch.tensor(range(64),requires_grad=False,dtype=torch.int32).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preactivate(x, n_int, positive=False, seq = False, causal_mask = None):\n",
    "    '''\n",
    "        x: 2D tensor of shape (batch_size, input_dim) or 3D tensor of shape (batch_size, seq_dim, input_dim) if seq is True\n",
    "        n_int: integer, number of intervals\n",
    "        positive: bool, whether to clip the input to [0,1]\n",
    "        causal_mask: bool, whether to use causal mask\n",
    "        reutrn: 3D tensor of shape (batch_size, input_dim, n_int+3) or 3D tensor of shape (batch_size, seq_dim, input_dim, n_int+3) if seq is True\n",
    "    '''\n",
    "    \n",
    "    device = x.device\n",
    "    global matrixA\n",
    "    matrixA = matrixA_empty.to(device)\n",
    "    if positive==True:\n",
    "        x = x.clip(0,1)\n",
    "    else:\n",
    "        x = x.clip(-1,1)\n",
    "    if seq == True:\n",
    "        batch_size = x.shape[0]\n",
    "        seq_dim = x.shape[1]\n",
    "        input_dim = x.shape[2]\n",
    "        output_shape = (batch_size,seq_dim,input_dim,n_int+3)\n",
    "        size = batch_size*seq_dim*input_dim\n",
    "    else:\n",
    "        batch_size = x.shape[0]\n",
    "        input_dim = x.shape[1]\n",
    "        output_shape = (batch_size,input_dim,n_int+3)\n",
    "        size = batch_size*input_dim\n",
    "    \n",
    "    x = x.view(-1)\n",
    "    #Select the adjacent control points\n",
    "    if positive==True:\n",
    "        gap = 1/n_int\n",
    "    else:\n",
    "        gap = 2/n_int\n",
    "    if positive==True:\n",
    "        coef_index  = torch.clip(torch.floor(x/gap).int(),max = n_int-1)\n",
    "    else:\n",
    "        coef_index  = torch.clip(torch.floor((x+1)/gap).int(),max = n_int-1) \n",
    "    \n",
    "    global coef_win_empty\n",
    "    if coef_win_empty.shape[0] < 4*size or coef_win_empty.shape[1] < n_int+3:\n",
    "        coef_win_empty = torch.zeros(4*size,n_int+3,requires_grad=False, device=device,dtype=torch.float)\n",
    "    coef_win = coef_win_empty[:4*size,:n_int+3].clone().to(device)\n",
    "    \n",
    "    global x_index_empty\n",
    "    if x_index_empty.shape[0] < 4*size:\n",
    "        x_index_empty = torch.tensor(range(4*size),requires_grad=False,dtype=torch.int32,device=device).contiguous()\n",
    "    x_index = x_index_empty[:4*size].to(device).contiguous()\n",
    "    \n",
    "    global win_matrix_empty\n",
    "    if win_matrix_empty.shape[0] < 4*size:\n",
    "        win_matrix_empty = win_matrix_base.repeat(4*size).int().to(device)\n",
    "    win_matrix = win_matrix_empty[:4*size].to(device)\n",
    "    \n",
    "    y_index = (coef_index.unsqueeze(1).expand(-1,4).contiguous().view(-1).int()+win_matrix).contiguous()\n",
    "    \n",
    "    coef_win.index_put_((x_index,y_index),torch.tensor(1,device=device,dtype=torch.float))\n",
    "    \n",
    "    if positive==True:\n",
    "        x = (x%gap/gap).unsqueeze(-1)\n",
    "    else:\n",
    "        x = ((x+1)%gap/gap).unsqueeze(-1)\n",
    "    \n",
    "    if seq == True and causal_mask is not None:\n",
    "        x = x.view(batch_size,seq_dim,input_dim,1)\n",
    "        mask = causal_mask[:,:seq_dim,:input_dim].view(1,seq_dim,input_dim,1)\n",
    "        x = torch.cat((torch.pow(x,3),torch.pow(x,2),x,torch.ones(size,1,device=device)),dim=-1) # (batch_size,seq_dim,input_dim,4)\n",
    "        x = x.masked_fill(mask==0,0)\n",
    "        x = x.view(batch_size*seq_dim*input_dim,4).unsqueeze(1) # (size,1,4)\n",
    "    else:    \n",
    "        x = torch.cat((torch.pow(x,3),torch.pow(x,2),x,torch.ones(size,1,device=device)),dim=-1).unsqueeze(1) # (size,1,4)\n",
    "\n",
    "    x = torch.matmul(x,matrixA)\n",
    "    x = torch.matmul(x,coef_win.view(size,4,n_int+3)).view(*output_shape)\n",
    "    return x\n",
    "    \n",
    "@torch.no_grad()\n",
    "def infer_coef(x, y, n_int, positive = False):\n",
    "    '''\n",
    "        x: 2D tensor of shape (batch_size, input_dim)\n",
    "        y: 2D tensor of shape (batch_size, output_dim)\n",
    "        n_int: integer, number of intervals\n",
    "        use the least square method to infer the coefficients\n",
    "    '''\n",
    "    device = x.device\n",
    "    y = y.to(device)\n",
    "    batch_size = x.shape[0]\n",
    "    input_dim = x.shape[1]\n",
    "    preact  = preactivate(x, n_int, positive).reshape(batch_size,-1) \n",
    "    coef = torch.linalg.lstsq(preact.to(device), y.to(device),\n",
    "                              driver='gelsd' if device == 'cpu' else 'gels').solution\n",
    "    coef = coef.reshape(input_dim,n_int+3,-1)\n",
    "    return coef\n",
    "\n",
    "def spline_forward(x: torch.Tensor, n_int: int, coef: torch.Tensor, positive = False):\n",
    "    '''\n",
    "        x: 2D tensor of shape (batch_size, input_dim)\n",
    "        n_int: integer, number of intervals\n",
    "        coef: 3D tensor of shape (input_dim, n_int+3, output_dim) \n",
    "    '''\n",
    "    batch_size = x.shape[0]\n",
    "    input_dim = x.shape[1]\n",
    "    output_dim = coef.shape[2]\n",
    "    device = x.device\n",
    "    coef = coef.to(device)\n",
    "    preact  = preactivate(x, n_int).to(device) # (batch_size, input_dim, n_int+3)\n",
    "    preact = preact.reshape(batch_size,input_dim*(n_int+3))\n",
    "    coef = coef.reshape(input_dim*(n_int+3),output_dim)\n",
    "    out = torch.matmul(preact,coef)\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the curve\n",
    "x = torch.linspace(-1,1,100).reshape(100,1,1) # (1000,1)\n",
    "x_int = 3\n",
    "coef = torch.tensor([[-2,0],[-1,-1],[0,0],[1,1],[2,0],[3,-1]],dtype=torch.float32, device='cpu').reshape(1,6,2)\n",
    "#coef = torch.randn(1,6,2,dtype=torch.float32,device='cuda')\n",
    "coef_1d = torch.tensor(range(6),dtype=torch.float32,device='cpu').reshape(1,6,1)\n",
    "y = spline_forward(x, x_int, coef)\n",
    "#y_1d  = spline_forward(x, x_int, coef_1d, 'cuda').to('cpu')\n",
    "plt.plot(y.numpy()[:,0],y.numpy()[:,1])\n",
    "#plt.plot(x.numpy(),y_1d.numpy())\n",
    "#plot the control points\n",
    "plt.scatter(coef[:,:,0].to('cpu').numpy(),coef[:,:,1].to('cpu').numpy())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the curve\n",
    "x = torch.linspace(-1,1,1000).unsqueeze(1)\n",
    "x_int = 12\n",
    "x_eval = torch.linspace(-1,1,12).unsqueeze(1)\n",
    "coef = infer_coef(x_eval,torch.randn(12,2,dtype=torch.float32,device='cuda'),12,'cuda')\n",
    "y = spline_forward(x, x_int, coef, 'cuda').to('cpu')\n",
    "plt.plot(y.numpy()[:,0],y.numpy()[:,1])\n",
    "# Plot the control points\n",
    "plt.scatter(coef[:,0].to('cpu').numpy(),coef[:,1].to('cpu').numpy())\n",
    "plt.show()\n",
    "print(infer_coef(x, y, x_int, 'cuda'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
